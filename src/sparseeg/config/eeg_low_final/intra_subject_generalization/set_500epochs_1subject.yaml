seed: [0, 1, 2, 3, 4]
train_percent: [0.01, 0.05, 0.1, 0.25, 0.5, 0.75]
valid_percent: 0.1
epochs: 500
save_dir: "set_500epochs_1subject_intra_subject_generalization"
dataset:
  type: "WAYEEGGALDataset-Low"
  batch_size: 0
  shuffle: true
  n_subjects: 1
model:
  type: "DenseMLP"
  hidden_layers: [[256, 256], [1024, 1024]]
  activations: [["relu", "relu"]]
  optim:
    type: "set"
    args: [[]]
    kwargs:
      drop_fraction_fn: [
        "lambda _: 0.15",
        "lambda _: 0.3",
      ] # Number of weights to prune at iter i
      scheduler:
        type: "PeriodicSchedule"
        args: []
        kwargs:
          update_freq: [25, 50, 75]
          update_start_step: 0
          update_end_step: null
      sparsity_distribution_fn:
        type: "erk"
        kwargs: [{"sparsity": 0.25}, {"sparsity": 0.5}] # Level of sparsity
    wrapped:
      type: "adam"
      args: [[]]
      kwargs:
        learning_rate: [0.01, 0.001, 0.0001]
